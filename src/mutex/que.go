package main

import (
	"fmt"
	"sync"
	"time"
)

const queueSize int = 5

func main() {
	// Текущая позиция записи в очередь
	var queueIndex int = 0
	// Текущее значение данных, которые помещаются в очередь
	var el int = 0
	c := sync.NewCond(&sync.Mutex{})
	// Создадим статический массив целых чисел
	// и будем следить за его переполнением
	queue := [queueSize]int{}
	deQueue := func() {
		c.L.Lock()
		time.Sleep(500 * time.Millisecond)
		// Чтобы вывод в консоль был не слишком быстрым,
		// добавляем искусственную задержку
		fmt.Printf("%s: %d\n", "Прочитан элемент", queue[0])
		for key := 0; key < len(queue)-1; key++ {
			queue[key] = queue[key+1]
		}
		c.L.Unlock()
		// Так как число взаимодействующих между собой горутин -
		// два,
		// достаточно вызывать метод Signal
		c.Signal()
	}

	for {
		// Наши две горутины используют общий ресурс. Вот здесь-то и
		// нужен внутренний локер для согласования доступа к
		// буферу,чтобы не получилось так,
		// что записывающая горутина ждала
		// высвобождения места в буфере, когда оно там и так есть
		c.L.Lock()
		if queueIndex == queueSize {
			c.Wait()
			queueIndex--
		}
		// Чтобы вывод в консоль быль не столько быстрым,
		// добавляем искусственную задержку
		time.Sleep(100 * time.Millisecond)
		queue[queueIndex] = el
		queueIndex++
		go deQueue()
		fmt.Printf("%s: %d\n", "Добавлено в очередь значение", el)
		el++
		// Обязательно разблокируем внутренний локер только после
		// добавления элемента в очередь,
		// иначе будет состояние гонки за данными:
		// считывающая горутина может считать данные, которых ещё
		// нет
		c.L.Unlock()
	}
}
